{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "import data_utils\n",
    "import model_utils\n",
    "from attack_utils import get_CSMIA_case_by_case_results, CSMIA_attack, LOMIA_attack\n",
    "from data_utils import oneHotCatVars, filter_random_data_by_conf_score\n",
    "from experiment_utils import MIAExperiment\n",
    "from disparity_inference_utils import get_confidence_array, draw_confidence_array_scatter, get_indices_by_group_condition, get_corr_btn_sens_and_out_per_subgroup, get_slopes, get_angular_difference, calculate_stds, get_mutual_info_btn_sens_and_out_per_subgroup\n",
    "from bcorr_utils import bcorr_sampling, evaluate, MLPClassifierFC\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.neural_network._base import ACTIVATIONS\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.inspection import permutation_importance\n",
    "from fairlearn.metrics import equalized_odds_difference, demographic_parity_difference\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tabulate\n",
    "import pickle\n",
    "import copy\n",
    "\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = {}\n",
    "\n",
    "i = -0.4\n",
    "j = -0.1\n",
    "experiment = MIAExperiment(sampling_condition_dict = \n",
    "    {\n",
    "            'subgroup_col_name': 'SEX',\n",
    "            'n': 25000,\n",
    "            'correlation_by_subgroup_values': [i, j],\n",
    "    }, shortname = f\"Corr_btn_sens_and_output_for_male_({i})_for_female_({j})\", random_state = 0\n",
    ")\n",
    "experiments[experiment.name] = experiment\n",
    "\n",
    "experiment_texas = MIAExperiment(sampling_condition_dict =\n",
    "    {\n",
    "            'subgroup_col_name': 'SEX_CODE',\n",
    "            'n': 25000,\n",
    "            'correlation_by_subgroup_values': [i, j],\n",
    "    }, shortname = f\"Corr_btn_sens_and_output_for_male_({i})_for_female_({j})\", random_state = 0, name = \"Texas100\", sensitive_column = 'ETHNICITY'\n",
    ")\n",
    "experiments[experiment_texas.name] = experiment_texas\n",
    "\n",
    "i = 0\n",
    "experiment_multi_valued = MIAExperiment(sampling_condition_dict = \n",
    "        {\n",
    "                'subgroup_col_name': 'ST',\n",
    "                'n': 1000,\n",
    "        }, random_state = i,\n",
    "        shortname = f\"Corr_btn_sens_and_output_for_ST_ranging_from_0_to_-0.5_random_state_{i}\"\n",
    "    )\n",
    "experiments[f\"{experiment_multi_valued.name}_multi_valued\"] = experiment_multi_valued\n",
    "\n",
    "subgroup_vals = [1, 2, 3, 4, 6, 20, 50, 51, 62, 63]\n",
    "experiment_multi_valued_texas = MIAExperiment(sampling_condition_dict = \n",
    "    {\n",
    "            'subgroup_col_name': 'PAT_STATUS',\n",
    "            'subgroup_values': subgroup_vals,\n",
    "            'n': 5000\n",
    "    }, shortname = f\"Corr_btn_sens_and_output_for_PAT_STATUS_ranging_from_0_to_-0.5\", name='Texas100', sensitive_column='SEX_CODE'\n",
    ")\n",
    "experiments[f\"{experiment_multi_valued_texas.name}_multi_valued\"] = experiment_multi_valued_texas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifier for experiment: Census19_subgroup_col_name_SEX_n_25000_correlation_by_subgroup_values_[-0.4, -0.1]_rs0\n",
      "Loaded classifier for experiment from file: Census19_subgroup_col_name_SEX_n_25000_correlation_by_subgroup_values_[-0.4, -0.1]_rs0\n",
      "Training classifier for experiment: Texas100_subgroup_col_name_SEX_CODE_n_25000_correlation_by_subgroup_values_[-0.4, -0.1]_rs0\n",
      "Loaded classifier for experiment from file: Texas100_subgroup_col_name_SEX_CODE_n_25000_correlation_by_subgroup_values_[-0.4, -0.1]_rs0\n",
      "Training classifier for experiment: Census19_subgroup_col_name_ST_n_1000_rs0\n",
      "Loaded classifier for experiment from file: Census19_subgroup_col_name_ST_n_1000_rs0\n",
      "Training classifier for experiment: Texas100_subgroup_col_name_PAT_STATUS_subgroup_values_[1, 2, 3, 4, 6, 20, 50, 51, 62, 63]_n_5000_rs42\n",
      "Loaded classifier for experiment from file: Texas100_subgroup_col_name_PAT_STATUS_subgroup_values_[1, 2, 3, 4, 6, 20, 50, 51, 62, 63]_n_5000_rs42\n"
     ]
    }
   ],
   "source": [
    "save_model=True\n",
    "for experiment_key in experiments:\n",
    "    experiment = experiments[experiment_key]\n",
    "    print(f\"Training classifier for experiment: {experiment}\")\n",
    "    try:\n",
    "        experiment.clf = model_utils.load_model(f'<PATH_TO_MODEL>/{experiment.ds.ds.filenameroot}_target_model.pkl')\n",
    "        print(f\"Loaded classifier for experiment from file: {experiment}\")\n",
    "    except:\n",
    "        base_model = model_utils.get_model(max_iter=500)\n",
    "        experiment.clf = copy.deepcopy(base_model)\n",
    "        experiment.clf.fit(experiment.X_train, experiment.y_tr_onehot)\n",
    "\n",
    "        if save_model:\n",
    "            model_utils.save_model(experiment.clf, f'<PATH_TO_MODEL>/{experiment.ds.ds.filenameroot}_target_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balancing Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15000, 22500]\n",
      "{0: {(0, 1): 4125, (0, 0): 3375, (1, 1): 3375, (1, 0): 4125}, 1: {(0, 1): 6187, (0, 0): 5062, (1, 1): 5063, (1, 0): 6188}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 22.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15000, 22500]\n",
      "{0: {(0, 1): 4125, (0, 0): 3375, (1, 1): 3375, (1, 0): 4125}, 1: {(0, 1): 6187, (0, 0): 5062, (1, 1): 5063, (1, 0): 6188}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 23.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000, 500, 980, 968, 960, 948, 940, 876, 920, 908, 900, 892, 656, 872, 860, 852, 840, 832, 820, 652, 800, 792, 784, 772, 764, 752, 504, 732, 724, 712, 704, 696, 684, 676, 480, 656, 644, 636, 624, 616, 604, 304, 588, 576, 568, 404, 548, 536, 528, 516, 348]\n",
      "{0: {(0, 1): 250, (0, 0): 250, (1, 1): 250, (1, 0): 250}, 1: {(0, 1): 125, (0, 0): 125, (1, 1): 125, (1, 0): 125}, 2: {(0, 1): 245, (0, 0): 245, (1, 1): 245, (1, 0): 245}, 3: {(0, 1): 242, (0, 0): 242, (1, 1): 242, (1, 0): 242}, 4: {(0, 1): 240, (0, 0): 240, (1, 1): 240, (1, 0): 240}, 5: {(0, 1): 237, (0, 0): 237, (1, 1): 237, (1, 0): 237}, 6: {(0, 1): 235, (0, 0): 235, (1, 1): 235, (1, 0): 235}, 7: {(0, 1): 219, (0, 0): 219, (1, 1): 219, (1, 0): 219}, 8: {(0, 1): 230, (0, 0): 230, (1, 1): 230, (1, 0): 230}, 9: {(0, 1): 227, (0, 0): 227, (1, 1): 227, (1, 0): 227}, 10: {(0, 1): 225, (0, 0): 225, (1, 1): 225, (1, 0): 225}, 11: {(0, 1): 223, (0, 0): 223, (1, 1): 223, (1, 0): 223}, 12: {(0, 1): 164, (0, 0): 164, (1, 1): 164, (1, 0): 164}, 13: {(0, 1): 218, (0, 0): 218, (1, 1): 218, (1, 0): 218}, 14: {(0, 1): 215, (0, 0): 215, (1, 1): 215, (1, 0): 215}, 15: {(0, 1): 213, (0, 0): 213, (1, 1): 213, (1, 0): 213}, 16: {(0, 1): 210, (0, 0): 210, (1, 1): 210, (1, 0): 210}, 17: {(0, 1): 208, (0, 0): 208, (1, 1): 208, (1, 0): 208}, 18: {(0, 1): 205, (0, 0): 205, (1, 1): 205, (1, 0): 205}, 19: {(0, 1): 163, (0, 0): 163, (1, 1): 163, (1, 0): 163}, 20: {(0, 1): 200, (0, 0): 200, (1, 1): 200, (1, 0): 200}, 21: {(0, 1): 198, (0, 0): 198, (1, 1): 198, (1, 0): 198}, 22: {(0, 1): 196, (0, 0): 196, (1, 1): 196, (1, 0): 196}, 23: {(0, 1): 193, (0, 0): 193, (1, 1): 193, (1, 0): 193}, 24: {(0, 1): 191, (0, 0): 191, (1, 1): 191, (1, 0): 191}, 25: {(0, 1): 188, (0, 0): 188, (1, 1): 188, (1, 0): 188}, 26: {(0, 1): 126, (0, 0): 126, (1, 1): 126, (1, 0): 126}, 27: {(0, 1): 183, (0, 0): 183, (1, 1): 183, (1, 0): 183}, 28: {(0, 1): 181, (0, 0): 181, (1, 1): 181, (1, 0): 181}, 29: {(0, 1): 178, (0, 0): 178, (1, 1): 178, (1, 0): 178}, 30: {(0, 1): 176, (0, 0): 176, (1, 1): 176, (1, 0): 176}, 31: {(0, 1): 174, (0, 0): 174, (1, 1): 174, (1, 0): 174}, 32: {(0, 1): 171, (0, 0): 171, (1, 1): 171, (1, 0): 171}, 33: {(0, 1): 169, (0, 0): 169, (1, 1): 169, (1, 0): 169}, 34: {(0, 1): 120, (0, 0): 120, (1, 1): 120, (1, 0): 120}, 35: {(0, 1): 164, (0, 0): 164, (1, 1): 164, (1, 0): 164}, 36: {(0, 1): 161, (0, 0): 161, (1, 1): 161, (1, 0): 161}, 37: {(0, 1): 159, (0, 0): 159, (1, 1): 159, (1, 0): 159}, 38: {(0, 1): 156, (0, 0): 156, (1, 1): 156, (1, 0): 156}, 39: {(0, 1): 154, (0, 0): 154, (1, 1): 154, (1, 0): 154}, 40: {(0, 1): 151, (0, 0): 151, (1, 1): 151, (1, 0): 151}, 41: {(0, 1): 76, (0, 0): 76, (1, 1): 76, (1, 0): 76}, 42: {(0, 1): 147, (0, 0): 147, (1, 1): 147, (1, 0): 147}, 43: {(0, 1): 144, (0, 0): 144, (1, 1): 144, (1, 0): 144}, 44: {(0, 1): 142, (0, 0): 142, (1, 1): 142, (1, 0): 142}, 45: {(0, 1): 101, (0, 0): 101, (1, 1): 101, (1, 0): 101}, 46: {(0, 1): 137, (0, 0): 137, (1, 1): 137, (1, 0): 137}, 47: {(0, 1): 134, (0, 0): 134, (1, 1): 134, (1, 0): 134}, 48: {(0, 1): 132, (0, 0): 132, (1, 1): 132, (1, 0): 132}, 49: {(0, 1): 129, (0, 0): 129, (1, 1): 129, (1, 0): 129}, 50: {(0, 1): 87, (0, 0): 87, (1, 1): 87, (1, 0): 87}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:02<00:00, 22.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5000, 4228, 4500, 3260, 4000, 3748, 1988, 1852, 3000, 2748]\n",
      "{0: {(0, 1): 1250, (0, 0): 1250, (1, 1): 1250, (1, 0): 1250}, 1: {(0, 1): 1057, (0, 0): 1057, (1, 1): 1057, (1, 0): 1057}, 2: {(0, 1): 1125, (0, 0): 1125, (1, 1): 1125, (1, 0): 1125}, 3: {(0, 1): 815, (0, 0): 815, (1, 1): 815, (1, 0): 815}, 4: {(0, 1): 1000, (0, 0): 1000, (1, 1): 1000, (1, 0): 1000}, 5: {(0, 1): 937, (0, 0): 937, (1, 1): 937, (1, 0): 937}, 6: {(0, 1): 497, (0, 0): 497, (1, 1): 497, (1, 0): 497}, 7: {(0, 1): 463, (0, 0): 463, (1, 1): 463, (1, 0): 463}, 8: {(0, 1): 750, (0, 0): 750, (1, 1): 750, (1, 0): 750}, 9: {(0, 1): 687, (0, 0): 687, (1, 1): 687, (1, 0): 687}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 27.41it/s]\n"
     ]
    }
   ],
   "source": [
    "for experiment_key in experiments:\n",
    "    experiment = experiments[experiment_key]\n",
    "    experiment.subgroup_col_name = experiment.sampling_condition_dict['subgroup_col_name']\n",
    "    experiment.subgroup_vals = [col.split('_')[-1] for col in experiment.X_train.columns if col.startswith(experiment.subgroup_col_name)]\n",
    "    p = -0.1 if len(experiment.subgroup_vals) == 2 else 0\n",
    "    experiment.X_train_balanced_corr, experiment.y_tr_balanced_corr, experiment.y_tr_onehot_balanced_corr = bcorr_sampling(experiment, experiment.X_train, experiment.y_tr, experiment.y_tr_onehot, subgroup_col_name=experiment.subgroup_col_name, p=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: Census19, Subgroup: SEX\n",
      "Correlations before balancing: {'0': -0.4, '1': -0.1}\n",
      "Correlations after balancing: {'0': -0.1, '1': -0.1}\n",
      "\n",
      "Dataset: Texas100, Subgroup: SEX_CODE\n",
      "Correlations before balancing: {'0': -0.4, '1': -0.1}\n",
      "Correlations after balancing: {'0': -0.1, '1': -0.1}\n",
      "\n",
      "Dataset: Census19, Subgroup: ST\n",
      "Correlations before balancing: {'0': 0.0, '1': -0.01, '2': -0.02, '3': -0.03, '4': -0.04, '5': -0.05, '6': -0.06, '7': -0.07, '8': -0.08, '9': -0.09, '10': -0.1, '11': -0.11, '12': -0.12, '13': -0.13, '14': -0.14, '15': -0.15, '16': -0.16, '17': -0.17, '18': -0.18, '19': -0.18, '20': -0.2, '21': -0.21, '22': -0.21, '23': -0.23, '24': -0.23, '25': -0.25, '26': -0.25, '27': -0.27, '28': -0.27, '29': -0.29, '30': -0.29, '31': -0.3, '32': -0.31, '33': -0.32, '34': -0.33, '35': -0.34, '36': -0.35, '37': -0.36, '38': -0.37, '39': -0.38, '40': -0.39, '41': -0.38, '42': -0.41, '43': -0.42, '44': -0.43, '45': -0.44, '46': -0.45, '47': -0.46, '48': -0.47, '49': -0.48, '50': -0.49}\n",
      "Correlations after balancing: {'0': 0.0, '1': -0.0, '2': -0.0, '3': -0.0, '4': 0.0, '5': 0.0, '6': 0.0, '7': 0.0, '8': 0.0, '9': -0.0, '10': 0.0, '11': 0.0, '12': -0.0, '13': 0.0, '14': 0.0, '15': -0.0, '16': -0.0, '17': 0.0, '18': 0.0, '19': -0.0, '20': 0.0, '21': -0.0, '22': -0.0, '23': -0.0, '24': 0.0, '25': 0.0, '26': 0.0, '27': -0.0, '28': -0.0, '29': 0.0, '30': 0.0, '31': -0.0, '32': -0.0, '33': 0.0, '34': -0.0, '35': -0.0, '36': 0.0, '37': 0.0, '38': -0.0, '39': -0.0, '40': -0.0, '41': 0.0, '42': 0.0, '43': -0.0, '44': -0.0, '45': -0.0, '46': -0.0, '47': 0.0, '48': 0.0, '49': 0.0, '50': 0.0}\n",
      "\n",
      "Dataset: Texas100, Subgroup: PAT_STATUS\n",
      "Correlations before balancing: {'1': -0.0, '2': 0.05, '3': 0.1, '4': 0.15, '6': 0.2, '20': 0.25, '50': 0.3, '51': 0.35, '62': 0.4, '63': 0.45}\n",
      "Correlations after balancing: {'1': -0.0, '2': 0.0, '3': 0.0, '4': 0.0, '6': 0.0, '20': 0.0, '50': 0.0, '51': 0.0, '62': -0.0, '63': 0.0}\n"
     ]
    }
   ],
   "source": [
    "for experiment_key in experiments:\n",
    "    experiment = experiments[experiment_key]\n",
    "    print(f\"\\nDataset: {experiment.name}, Subgroup: {experiment.subgroup_col_name}\")\n",
    "    correlations_dict_before = {val: round(get_corr_btn_sens_and_out_per_subgroup(experiment, experiment.X_train, experiment.y_tr, {experiment.subgroup_col_name: val}), 2) for val in experiment.subgroup_vals}\n",
    "    print(f\"Correlations before balancing: {correlations_dict_before}\")\n",
    "    correlations_dict_after = {val: round(get_corr_btn_sens_and_out_per_subgroup(experiment, experiment.X_train_balanced_corr, experiment.y_tr_balanced_corr, {experiment.subgroup_col_name: val}), 2) for val in experiment.subgroup_vals}\n",
    "    print(f\"Correlations after balancing: {correlations_dict_after}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifier for experiment: Census19_subgroup_col_name_SEX_n_25000_correlation_by_subgroup_values_[-0.4, -0.1]_rs0\n",
      "Loaded classifier for experiment from file: Census19_subgroup_col_name_SEX_n_25000_correlation_by_subgroup_values_[-0.4, -0.1]_rs0\n",
      "Training classifier for experiment: Texas100_subgroup_col_name_SEX_CODE_n_25000_correlation_by_subgroup_values_[-0.4, -0.1]_rs0\n",
      "Loaded classifier for experiment from file: Texas100_subgroup_col_name_SEX_CODE_n_25000_correlation_by_subgroup_values_[-0.4, -0.1]_rs0\n",
      "Training classifier for experiment: Census19_subgroup_col_name_ST_n_1000_rs0\n",
      "Loaded classifier for experiment from file: Census19_subgroup_col_name_ST_n_1000_rs0\n",
      "Training classifier for experiment: Texas100_subgroup_col_name_PAT_STATUS_subgroup_values_[1, 2, 3, 4, 6, 20, 50, 51, 62, 63]_n_5000_rs42\n"
     ]
    }
   ],
   "source": [
    "save_model=True\n",
    "for experiment_key in experiments:\n",
    "    experiment = experiments[experiment_key]\n",
    "    print(f\"Training classifier for experiment: {experiment}\")\n",
    "    try:\n",
    "        experiment.clf_balanced_corr = model_utils.load_model(f'<PATH_TO_MODEL>/{experiment.ds.ds.filenameroot}_target_model_bcorr.pkl')\n",
    "        print(f\"Loaded classifier for experiment from file: {experiment}\")\n",
    "    except:\n",
    "        base_model = model_utils.get_model(max_iter=500)\n",
    "        experiment.clf_balanced_corr = copy.deepcopy(base_model)\n",
    "        experiment.clf_balanced_corr.fit(experiment.X_train_balanced_corr, experiment.y_tr_balanced_corr)\n",
    "\n",
    "        if save_model:\n",
    "            model_utils.save_model(experiment.clf_balanced_corr, f'<PATH_TO_MODEL>/{experiment.ds.ds.filenameroot}_target_model_bcorr.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fairness Constraint Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading mitigator for experiment: Census19_subgroup_col_name_SEX_n_25000_correlation_by_subgroup_values_[-0.4, -0.1]_rs0\n",
      "Loading mitigator for experiment: Texas100_subgroup_col_name_SEX_CODE_n_25000_correlation_by_subgroup_values_[-0.4, -0.1]_rs0\n"
     ]
    }
   ],
   "source": [
    "from fairlearn.reductions import ExponentiatedGradient, DemographicParity, EqualizedOdds, ErrorRate\n",
    "\n",
    "for experiment_key in experiments:\n",
    "    experiment = experiments[experiment_key]\n",
    "\n",
    "    if len(experiment.subgroup_vals) > 2:\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        print(f\"Loading mitigator for experiment: {experiment}\")\n",
    "        experiment.mitigator = model_utils.load_model(f'<PATH_TO_MODEL>/{experiment.ds.ds.filenameroot}_target_model_fairness_constraints.pkl')\n",
    "    except:\n",
    "        print(f\"Training mitigator for experiment: {experiment}\")\n",
    "        clf2 = MLPClassifierFC(max_iter=500)\n",
    "        clf2.coefs_ = experiment.clf.coefs_\n",
    "        clf2.intercepts_ = experiment.clf.intercepts_\n",
    "        constraint = EqualizedOdds()\n",
    "        experiment.mitigator = ExponentiatedGradient(clf2, constraint)\n",
    "\n",
    "        experiment.mitigator.fit(experiment.X_train, experiment.y_tr, sensitive_features=experiment.X_train[f'{experiment.subgroup_col_name}_0'])\n",
    "\n",
    "        model_utils.save_model(experiment.mitigator, f'<PATH_TO_MODEL>/{experiment.ds.ds.filenameroot}_target_model_fairness_constraints.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Census19, Subgroup: SEX\n",
      "           ASRD_CSMIA  ASRD_LOMIA     EOD     DPD      MA\n",
      "w/o BCorr       11.80       14.65  0.0726  0.1284  73.904\n",
      "w Bcorr          0.42        1.01  0.0438  0.0914  73.770\n",
      "FC               8.94       13.97  0.0566  0.1059  70.598\n",
      "Dataset: Texas100, Subgroup: SEX_CODE\n",
      "           ASRD_CSMIA  ASRD_LOMIA     EOD     DPD      MA\n",
      "w/o BCorr       12.91       15.45  0.1768  0.1007  72.080\n",
      "w Bcorr          1.34        0.87  0.0120  0.0701  74.624\n",
      "FC              11.65       11.65  0.1012  0.0288  70.578\n",
      "Dataset: Census19, Subgroup: ST\n",
      "           ASRD_CSMIA  ASRD_LOMIA  EOD     DPD         MA\n",
      "w/o BCorr       23.22       25.78  1.0  0.1757  73.576448\n",
      "w Bcorr         14.12       10.89  1.0  0.1471  71.908570\n",
      "Dataset: Texas100, Subgroup: PAT_STATUS\n",
      "           ASRD_CSMIA  ASRD_LOMIA     EOD     DPD         MA\n",
      "w/o BCorr       17.06       19.00  0.8184  0.2681  74.544221\n",
      "w Bcorr          8.68        4.74  0.7886  0.1906  74.290342\n"
     ]
    }
   ],
   "source": [
    "for experiment_key in experiments:\n",
    "    experiment = experiments[experiment_key]\n",
    "    res_dict = {\n",
    "        'w/o BCorr': evaluate(experiment, experiment.clf, experiment.X_train, experiment.y_tr, experiment.X_test, experiment.y_te, subgroup_col_name=experiment.subgroup_col_name),\n",
    "        'w Bcorr': evaluate(experiment, experiment.clf_balanced_corr, experiment.X_train_balanced_corr, experiment.y_tr_balanced_corr, experiment.X_test, experiment.y_te, subgroup_col_name=experiment.subgroup_col_name)\n",
    "    }\n",
    "    if len(experiment.subgroup_vals) == 2:\n",
    "        res_dict['FC'] = evaluate(experiment, experiment.mitigator, experiment.X_train, experiment.y_tr, experiment.X_test, experiment.y_te, subgroup_col_name=experiment.subgroup_col_name)\n",
    "    res_dict_df = pd.DataFrame.from_dict(res_dict, orient='index')\n",
    "    print(f\"Dataset: {experiment.name}, Subgroup: {experiment.subgroup_col_name}\")\n",
    "    print(res_dict_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tabular",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
